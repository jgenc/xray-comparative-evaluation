# Scripts

## Configuration notes

Before the training and testing process, you should adapt the provided configuration files in `dino/cfg`. For example, in order to train DINO on `CLCXray` you will have to do the following changes:
1. Modify all instances of `data_root` to point to the correct dataset path. It is strongly recommended to use absolute paths
2. Modify all instances of `ann_file` to point to the correct COCO-style annotation file. Be aware that the `test`, `val` and `train` dictionary entries of `data` should point to the correct annotation files. Do not replace *all* instances at once! It is strongly recommended to use absolute paths.
3. `img_prefix` is an absolute path to the data files (the folder with the images). Be aware that the `test`, `val` and `train` dictionary entries of `data` should point to the correct folder, if the folder structure is different for each case. Do not replace *all* instances at once!
4. Although in the provided configurations it's correct, the `classes` attribute should be changed *if you want to train using some other kind of dataset*! Be aware that the `test`, `val` and `train` dictionary entries of `data` should all have the correct `classes` attribute.
5. **You need to set the correct Swin backbone path for the scripts to work! It is relative to the working directory of the executed training or testing script.**
6. If you are continuing training from a previous experiment, you should change `load_from` from `None` to a string pointing to the absolute path of the weights file you want to continue from.

## Training

**Normal (Single-GPU)**

```bash
python ./mmdetection/tools/train.py \
  /path/to/cfg \
  --work-dir /path/to/training/files/output
```

* The first argument is reserved for the training configuration file. You can find these in `co-detr/cfg`
* `--work-dir` is where the training log files, configuration copy, and weights should be saved

**Distributed (Multi-GPU)**

```bash
./mmdetection/tools/dist_train.sh \
  ./path/to/cfg \
  N \
  /path/to/training/files/output
```

* The first argument is reserved for the training configuration file. You can find these in `co-detr/cfg`
* The second argument `N` refers to number of GPUs to be used.
* The third argument  is where the training log files, configuration copy, and weights should be saved

## Resume a training

To resume a training just append the `--auto-resume` flag if it's in the exact same directory.
Otherwise, you can also use the `--resume-from` flag, targeting a specific weight file to resume
the training from.

Below is an example of `--auto-resume` for multi-GPU training:

```bash
./tools/dist_train.sh \
  /path/to/cfg \
  N \
  /path/to/training/files/output \
  --auto-resume
```

## Testing

To test a model on the test set, run the following command:

**Normal (Single-GPU)**

```bash
python 
  /path/to/training/config/file \
  /path/to/weights/file \
  --work-dir /path/to/test/files/output \
  --eval bbox \
  --out /path/to/results.pkl \
```

* The first argument should point to the training configuration file. In this case you should use the one generated by the [training](#training) step, as it modifies some paths. If you choose to use another configuration file, make sure you modify the dataset paths accordingly.
* The second argument should point to the weights/model you want to evaluate on the test set. Usually the best weights are used.
* `--work-dir` is where the testing log files are going to be saved. A good practice is to include `--out` in this folder.
* `--eval` indicates what the evaluation metric should be based on. Leave as `bbox`.
* `--out` should point to your desired output path of a `.pkl` file. This file can be used for further analysis, such as graph creation (see the `tools` folder for that).


**Distributed (Multi-GPU)**

```bash
./mmdetection/tools/dist_test.sh \
  /path/to/training/config/file \
  /path/to/weights/file \
  N \
  --work-dir /path/to/test/files/output \
  --eval bbox \
  --out /path/to/results.pkl \
```

* The first argument should point to the training configuration file. In this case you should use the one generated by the [training](#training) step, as it modifies some paths. If you choose to use another configuration file, make sure you modify the dataset paths accordingly.
* The second argument should point to the weights/model you want to evaluate on the test set. Usually the best weights are used.
* The third argument `N` refers to number of GPUs to be used.
* `--work-dir` is where the testing log files are going to be saved. A good practice is to include `--out` in this folder.
* `--eval` indicates what the evaluation metric should be based on. Leave as `bbox`.
* `--out` should point to your desired output path of a `.pkl` file. This file can be used for further analysis, such as graph creation (see the `tools` folder for that).
